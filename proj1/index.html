<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2018</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Riya Kumar and Mylinh Vu, CS184-??</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>Give a high-level overview of what you implemented in this project. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the project.</p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>
<p> For task 1, we implemented basic triangle rasterization. Three points of a triangle are passed into the function. Our algorithm finds the maximum and minnimum of the x-values and y-values given. 
  The rest of the rasterization is implemented in task 2. Our algorithm is no worse than one that checks each sample within the bounding box of the triangle because we are also just finding the bounds.
  It is no more or less efficient. You will see from the pixel inspector that the edges and corners of this images are pixelated rather than blurred. We later implement a fix for this problem.</p>


<p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="proj1/task1image" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
      <td>
        <img src="proj-webpage-template/proj1/task1image" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="images/image3.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
      <td>
        <img src="images/image4.png" align="middle" width="400px"/>
        <figcaption align="middle">Caption goes here.</figcaption>
      </td>
    </tr>
  </table>
</div>


<h3 align="middle">Part 2: Antialiasing triangles </h3>
<p> For task 2, we built out our implementation of rasterizing basic triangles to include super-sampling. </p>



<h3 align="middle">Part 3: Transforms</h3>



<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3> 
  <p> Barycentric coordinates translate points in the (x,y) coordinate system to the (alpha, beta, gamma) coordinate system. Using the 
    (alpha, beta, gamma) barycentric coordinate system, we can use the colors of the vertices of a triangle to find the weighted average and assign the
    the color of some pixel within the triangle. </p>


<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>
  
  <p> Pixel sampling allows us to map textures to our images. The process entails recieving a triangle that was passed in,
    evaluating what texture should be at that sample, and applying the texture to the specific pixels as a color </p>
  <p>We find the barycentric coordinates because the image is in (x,y) coordinates and we need to transform to the texutres (u,v) coordinates.
    By interpolating with the barycentric coordinates and the triangles original coordinates, we can get our desired position in (u,v) coordinates. 
    From here, we can assign the texture using either the sample_nearest or sample_bilinear algorithm. 
  <p> For nearest sampling, we first check to make sure the level is valid, returning magenta if not. Then we set the pixel's color in (x,y) coordinates, to the closest corresponding texel in (u,v) coordinates.</p>
  <p> For bilinear sampling, we first check to make sure the level is valid, returning the color magenta to indicate error if not. 
    From the point passed in, we then find the four nearest sample locations. These are the center points of the four texels closest to the point in (u,v) coordinates.
    We interpolate from these four texels to get the average texel color and map it to our pixel in (x,y).</p>
  <p> We see the biggest difference between the sampling methods when working with images with only a few colors. Nearest neighbor can improperly represent pixels because it only takes one sample. Nearest
    neighbor is better for sampling when you want a crisper image especially with groups of the same color. Bilinear is better for accurately representing an image, even if it does produce a blurrier image. </p>


<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>
<p>Level sampling determines how close or far away the part of the image is to determine how high resolution the image needs to be. 
  This is utilized through mipmap levels: higher mipmap levels (0-7) mean lower resolution the pixel will be more of an average of the surroudning pixels
  and lower pixels will be higher resolution. Level 0 is the highest resolution for the image.</p>
<p>To implement this, we have to determine which mipmap level it is on by converting the pixel coordinates (x, y) to their texture coordinate coordinates (u,v).
  We calculated (x, y), (x+1, y), and (x, y+1) for all pixels that have these points to find the partial derivatives of x and y. By taking the log base 2 of the max 
  of the norms of the vectors created by the translated points of (x, y) and (x+1, y) and points (x, y) and (x, y+1), we find our level. We can choose 2 different
  level determining methods of nearest level to the calculated value or through linear interpolation that takes the 2 colors of sampling at the level above and below
  and getting the weighted average based on their distance from that level. </p>
<p>By speed and memory, single pixel sampling is more efficient than supersampling since it doesn't have to get the high resolution image and downsample with a larger memory
    sample buffer. However, by supersampling, jaggies are less obvious and there is less antialiasing. For pixel sampling, using the nearest method is better with speed and memory
    since it only needs to utilize one texture into account; however, bilinear interpolation improves the quality of the picture by sampling and averaging the values around the point.
    With level sampling, level 0 at default is fastest with the least amount of memory used, but provides and aliased picture. Level nearest samples improves the image with antialiasing, 
    but it takes more time and memory than level 0 sampling. Finally, linear level interpolation reduces antialiasing the most, but it utilizes the most memory and speed.</p>



<h2 align="middle">Section III: Art Competition</h2>
<p>If you are not participating in the optional art competition, don't worry about this section!</p>

<h3 align="middle">Part 7: Draw something interesting!</h3>

</body>
</html>
