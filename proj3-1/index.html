<html>
	<head>
		<style>
  			body {
    				padding: 100px;
    				width: 1000px;
    				margin: auto;
    				text-align: left;
    				font-weight: 300;
    				font-family: 'Open Sans', sans-serif;
    				color: #121212;
  			}
  			h1, h2, h3, h4 {
    				font-family: 'Source Sans Pro', sans-serif;
  			}
		</style>
		<title>CS 184 MeshEdit</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
	</head>
	
	<body>
		<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
		<h1 align="middle">Project 3: PathTracer</h1>
		<h2 align="middle">Riya Kumar and Mylinh Vu, CS184-rm</h2>

		<br><br>

		<div>

		<h2 align="middle">We implemented the core routines of a physically-based renderer using a pathtracing algorithm.
			We used the formulas we learned in lecture to design and build the algorithms. It is interesting to note that a 
			seemingly simple formula can get complicated when working with vectors. It is cool that we can now generate realistic pictures.
			We found this project to be rewarding. However, debugging is quite difficult and rendering takes more time than anticipated.</h2>
			<p></p>


		<h2 align="middle">Part I: Ray Generation and Scene Intersection</h2>
			Walk through the ray generation and primitive intersection parts of the rendering pipeline
			<p>To generate a camera ray, normalized coordinates need to be transformed into camera space. 
				From there, we can generate a ray in camera space that will be converted into a ray in world space. 
				With the ray, then we can determine what rays intersect either the pixel or shape. In this task, 
				we implemented triangle and sphere intersection.</p>
			<p>For triangle intersection, we utilized the Moller-Trumbore intersection algorithm. This algorithm 
				takes in the equations of the ray and the triangle and set them equal to each other. From there, 
				we calculated edges (e1 and e2) and spaces (s, s1, s2). With these values, we can find the arbitrary 
				values of t, b1, and b2 which will determine if the ray intersects the triangle. If b1 and b2 are 
				between 0 and 1 and 1 is within the range of the ray, then the ray intersected the triangle. </p>

		<div align="middle">
			<table style="width=100%">
			<tr>
				<td>
					<img src="banana.png" align="middle" width="400px"/>
					<figcaption align="middle">Generating Pixel Samples for Banana</figcaption>
				</td>
				<td>
					<img src="CBemptyGradient.png" align="middle" width="400px"/>
					<figcaption align="middle">Generating Pixel Samples for CBEmpty</figcaption>
				</td>
			</tr>
			<br>
			<tr>
				<td>
					<img src="CBempty.png" align="middle" width="400px"/>
					<figcaption align="middle">Rendering with Ray-Triangle Intersection</figcaption>
				</td>
				<td>
					<img src="CBspheres.png" align="middle" width="400px"/>
					<figcaption align="middle">Rendering with Ray-Sphere Intersection</figcaption>
				</td>
			</tr>
			<tr>
				<td>
					<img src="bananaRender.png" align="middle" width="400px"/>
					<figcaption align="middle">More Scene Rendering</figcaption>
				</td>
				<td>
					<img src="CBbunny.png" align="middle" width="400px"/>
					<figcaption align="middle">Bunny Rendering</figcaption>
				</td>
			</tr>	
			</table>
		</div>
			
		<h2 align="middle">Part 2: Bounding Volume Hierarchy</h2>
			<p> In order to construct the BVH, we find the number of primitives given to us. If there are less primitives
				than allowed for the max leaf size, we simply create a leaf node by specifying a new start and end for
				the node. The left and right values will be null since it is a leaf. However, if there are more primitves than
				the allowed for a leaf node, then we have to divide the leaf nodes into a right and left side and use recursion. 
				We find the average for all the primitives which will later use to compare against the centroids. We do this by creating
				a 0 vector in the x, y, and z direction and looping through all the primitives. We add each primitives' bbox's centroid to
				our average so it is representitive of all the primitives. We divide this sum by the number of primitives to get the average.
				Our next step is to figure out what axis to split on that gives us the most benefit.
				
				For each axis, we start by dividing all the primitives into the category of right or left based on how their centroid compares to our average centroid value for that axis that we calculated
				eariler. We then build each primitives bbox. We find the extent, or the difference between the max and min of each bbox. We use the extent
				to find the left hueristic and the right hueristic. We can sum these to find the overall hueristic. Since this new hueristic is made up of
				both the left and right sides, we can compare this against the overall smallest_surface_area_hueristic. The hueristic will be compared to the
				hueristic for all this axis so whichever is smallest of the axis will prevail. 
				
				So once we know which axis it is most benneficial to split on, we prepare for recursion. We set the left primitives and right primitives
				to those of the axis it is most benneficial to split on. We do that by iterating through all the primtiives, like in the previous step, only this
				time we are getting the bbox's centroid on the most benneficial axis and comparing it to the average of the most beneficial axis aswell. 
				
				Once that's done, we just need to find the proper iterators to pass into the recursive call. For left recursive call, we can use start, but then we need
				to create a center left iterator for the call to use as an end iterator. We do this by iterating through the  number of primitives and assigning values
				to the left and right iterators. For the right recursive call, we can start off at the left center iterator, but then we can use the end iterator. For both calls
				we can use the max_leaf_size that was given. After the recursion comes up with lists that are smaller than the max leaf size, we will get leaf nodes returned from the
				bottom up. 
				
			</p>
			
			<p>
				Here are some large .dae files that are too large to render without BVH.
			</p>
			
			<div align="middle">
			<table style="width=100%">
			<tr>
				<td>
					<img src="part2_image1.png" align="middle" width="400px"/>
					<figcaption align="middle">Complicated image with normal shading</figcaption>
				</td>
				<td>
					<img src="part2_image2.png" align="middle" width="400px"/>
					<figcaption align="middle">Complicated image with normal shading</figcaption>
				</td>
				<td>
					<img src="part2_image_3.png" align="middle" width="400px"/>
					<figcaption align="middle">Complicated image with normal shading</figcaption>
				</td>
			</tr>
		
		</table>
	</div>
			<p> 
				Generating the cow.dae file with BVH takes 0.1703 seconds to render. However, generating the image without BVH takes 50.4463 seconds. Generating the beetle.dae file with BVH takes 0.1136 seconds to render, but without
				 BVH it takes 73.3020 seconds. For both moderately complex scenes, it takes significantly longer to render images without BVH than with BVH. 
			</p>
		<h2 align="middle">Part 3: Direct Illumination</h2>
			<p>In direct uniform hemisphere sampling, we use the hemisphere sampling to determine which direction to sample from for hit_p. 
				To do so, we iterate through the number of samples and average the irradiances between each ray that we find. 
				To solve for the irradiance, we check if the ray intersects an object. If it does, then we multiply its emission, BSDF, and the cosine of 
				the angle between hit_p normal and the ray. Afterwards, we divide by the pdf which in this case is 1/(2*PI). The average of the irradiances 
				produces an illuminated image at each hit_p.</p>
			<p>In direct importance sampling, we iterate through all the light rays in the scene which increases the samples we utilize. We first determine 
				if the light is a delta light, meaning that it comes from the light source. If it is a delta light, then we only sample it once. 
				Otherwise, we sample it by the number of samples that the input provides. With each sample we determine the irradiance in a similar 
				method to the hemisphere sampling method by multiplying the light radiance by the BDSF and the angle between the hit_p normal and ray. Then, 
				we divide it by its respective pdf. When we iterate through the number of samples, we also average the irradiances to get the illumniation value for 
				the specific hit_p. With more light ray samples, the less noise that is depicted in the image since we can average the illumination better with more samples taken. </p>
			
			<div align="middle">
				<table style="width=100%">
				<tr>
					<td>
						<img src="bunny_1_1.png" align="middle" width="400px"/>
						<figcaption align="middle">1 Light Ray with 1 Sample</figcaption>
					</td>
					<td>
						<img src="bunny_4_1.png" align="middle" width="400px"/>
						<figcaption align="middle">4 Light Rays with 1 Sample</figcaption>
					</td>
				</tr>
				<br>
				<tr>
					<td>
						<img src="bunny_16_1.png" align="middle" width="400px"/>
						<figcaption align="middle">16 Light Rays with 1 Sample</figcaption>
					</td>
					<td>
						<img src="bunny_64_1.png" align="middle" width="400px"/>
						<figcaption align="middle">64 Light Rays with 1 Sample</figcaption>
					</td>
				</tr>	
				</table>
			</div>
				
			<p>The images for the light sampling differ as the one rendered from the uniform hemisphere sampling produces more noise in comparison to the importance 
				light sampling which appears smoother. The uniform hemisphere sampling produces more noise since the samples are only taken from the hemisphere area 
				that is centered around our object or point of interest. Because we are taking less samples and centered a specific point, there are more chances for 
				rays to have zero irradiance which causes the pixelated noise. In comparison, the importance light sampling is taking samples from all the rays in the 
				scene, including the light source which decreases the noise. With more samples taken in comparison, it reduces the chances for noise as well. The tradeoff 
				with the better produced image in the time it takes to render. </p>
			
			<div align="middle">
				<table style="width=100%">
				<tr>
					<td>
						<img src="bunny_64_32_hem.png" align="middle" width="400px"/>
						<figcaption align="middle">Uniform Hemisphere Sampling</figcaption>
					</td>
					<td>
						<img src="bunny_64_32_light.png" align="middle" width="400px"/>
						<figcaption align="middle">Importance Light Sampling</figcaption>
					</td>
				</tr>
				</table>
			</div>
			
		<h2 align="middle">Part 4: Global Illumination</h2>
			<p>Global illuminations utilized the at_least_one_bounce function to iterate through the bounces to illuminate the scene with the accumilation of direct and indirect 
				lighting. To get the direct lighting, we call the one_bounce_radiance function as our basis of light. Then, we want to check the input depth to determine if the 
				ray and how many bounces it has taken. It the ray hasn't taken as many bounces as the max ray depth, then we employ the Russian Roulette method which take the 
				continuation probability of .7 and determines whether the ray should continue tracing. This allows to us to sample enough rays for the image, but still increase 
				efficiency by still limiting the values it continues to evaluate. If the ray continues to be traced, then we take the sample from hit_p and use recursion by calling 
				the same function, at_least_one_bounce_radiance, but decrease the depth value in order to track the bounces that the ray has already taken. We then solve the the irrradiance 
				from the indirect light wth the same formula by multiplying the value by BSDF, the cosing of the hit_p normal and ray. However, this time we divide by both the pdf and 
				continuation probability (cpdf). This irradiance gets factored into the global illumination and averaged out to produce the illuminated image. </p>
			
		<p> The next two images depict one scene with only either direct illumination or indirect illumination. </p>
			<div align="middle">
			<table style="width=100%">
			<tr>
				<td>
					<img src="part_4_Lout.png" align="middle" width="400px"/>
					<figcaption align="middle">Only direct illumination</figcaption>
				</td>
				<td>
					<img src="part4_one_bounce.png" align="middle" width="400px"/>
					<figcaption align="middle">only indirect illumination</figcaption>
				</td>
			</tr>
		</table>
				
		<div align="middle">
			<table style="width=100%">
				<tr>
					<td>
						<img src="bunny_mrd_0.png" align="middle" width="400px"/>
						<figcaption align="middle">Bunny Rendering of Max Ray Depth 0</figcaption>
					</td>
					<td>
						<img src="bunny_mrd_1.png" align="middle" width="400px"/>
						<figcaption align="middle">Bunny Rendering of Max Ray Depth 1</figcaption>
					</td>
				</tr>
				<br>
				<tr>
					<td>
						<img src="bunny_mrd_2.png" align="middle" width="400px"/>
						<figcaption align="middle">Bunny Rendering of Max Ray Depth 2</figcaption>
					</td>
					<td>
						<img src="bunny_mrd_3.png" align="middle" width="400px"/>
						<figcaption align="middle">Bunny Rendering of Max Ray Depth 3</figcaption>
					</td>
				</tr>
				<br>
				<tr>
					<td>
						<img src="bunny_mrd_100.png" align="middle" width="400px"/>
						<figcaption align="middle">Bunny Rendering of Max Ray Depth 100</figcaption>
					</td>
				</tr>
					
				</table>
			</div>
		</div>
			
			<p> The following table shows one scene rendered with various sample per pixel rates with 4 light rays. </p>
			<div align="middle">
				<table style="width=100%">
				<tr>
					<td>
						<img src="sample_per_pixel_1.png" align="middle" width="400px"/>
						<figcaption align="middle">1 Sample per Pixel</figcaption>
					</td>
					<td>
						<img src="sample_per_pixel_2.png" align="middle" width="400px"/>
						<figcaption align="middle">2 Samples per Pixel</figcaption>
					</td>
				</tr>
				<br>
				<tr>
					<td>
						<img src="sample_per_pixel_4.png" align="middle" width="400px"/>
						<figcaption align="middle">4 Samples per Pixel</figcaption>
					</td>
					<td>
						<img src="sample_per_pixel_8.png" align="middle" width="400px"/>
						<figcaption align="middle">8 Samples per Pixel</figcaption>
					</td>
				</tr>
				<br>
				<tr>
					<td>
						<img src="sample_per_pixel_16.png" align="middle" width="400px"/>
						<figcaption align="middle">16 Samples per Pixel</figcaption>
					</td>
					<td>
						<img src="sample_per_pixel_32.png" align="middle" width="400px"/>
						<figcaption align="middle">32 Samples per Pixel</figcaption>
					</td>
				</tr>
				<br>
				<tr>
					<td>
						<img src="sample_per_pixel_64.png" align="middle" width="400px"/>
						<figcaption align="middle">64 Samples per Pixel</figcaption>
					</td>
					<td>
						<img src="sample_per_pixel_1024.png" align="middle" width="400px"/>
						<figcaption align="middle">1024 Samples per Pixel</figcaption>
					</td>
				</tr>
					
				</table>
			</div>
		
		
		<h2 align="middle">Part 5: Adaptive Sampling</h2>
			<p>For adaptive sampling, we start by setting up all the variables we will need based on the formula
			given in class. Then, we run through each of the sample, incrementing the batch size at the end of each loop to keep an
				accurate count. We see if a pixel has converged every samplesPerBatch pixels by comparing 
			the batch size and samples per batch at the beginning of each sample loop. If so, we update the neccesary variables
			for the equations such as mu and mu squared. Then, we get the adjusted origin, the ray, the max ray depth, and the estimated radiance
			global illumination for that ray, for that sample. We also keep track of the s1 and s2 variable by saving that illumination and the
			illumination squared. We keep track of the average my adding the illumination to the average and dividing by the number of samples.
			We then update the sample buffer and the sample count buffer to reflect the sampling rate colors for different areas. </p>
			
			<div align="middle">
				<table style="width=100%">
				<tr>
					<td>
						<img src="part5_bunny1.png" align="middle" width="400px"/>
						<figcaption align="middle">Image of Bunny</figcaption>
					</td>
					<td>
						<img src="part5_bunny2.png" align="middle" width="400px"/>
						<figcaption align="middle">4 Light Rays with 1 Sample</figcaption>
					</td>
				</tr>
				<br>
				<tr>
					<td>
						<img src="part5_dragon1.png" align="middle" width="400px"/>
						<figcaption align="middle">16 Light Rays with 1 Sample</figcaption>
					</td>
					<td>
						<img src="part5_dragon2.png" align="middle" width="400px"/>
						<figcaption align="middle">64 Light Rays with 1 Sample</figcaption>
					</td>
				</tr>	
				</table>
			</div>
			
	</body>
</html>
